{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42005962-d4ae-4a1a-88ed-459bb488afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zacks/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This notebook is adapted for WSL, adb commands are different than in Linux environments\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoConfig, AutoProcessor\n",
    "\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from common_files.nsptargets import NspTargets\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e49c2b-7202-4c0a-8cdf-b9da7aced61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contestant's upload files passed validation\n"
     ]
    }
   ],
   "source": [
    "# Check and initialize paths to files in contestant_uploads/\n",
    "# contestant_uploads/\n",
    "# ├── ar*-ar*-cl*\n",
    "# │   └── weight_sharing_model_*_of_*.serialized.bin\n",
    "# ├── embedding_weights*.raw\n",
    "# ├── inputs.json\n",
    "# ├── mask.raw\n",
    "# ├── position_ids_cos.raw\n",
    "# ├── position_ids_sin.raw\n",
    "# ├── serialized_binaries\n",
    "# │   └── veg.serialized.bin\n",
    "# └── tokenizer.json\n",
    "\n",
    "execution_ws = os.getcwd()\n",
    "context_path = execution_ws + \"/contestant_uploads\"\n",
    "missing = []\n",
    "\n",
    "# ---- Find ar*-ar*-cl* folders ----\n",
    "ar_folders = glob.glob(os.path.join(context_path, \"ar*-ar*-cl*\"))\n",
    "ar_folders = [f for f in ar_folders if os.path.isdir(f)]\n",
    "\n",
    "if len(ar_folders) == 0:\n",
    "    missing.append(\"ar*-ar*-cl* folder\")\n",
    "elif len(ar_folders) > 1:\n",
    "    raise RuntimeError(\n",
    "        f\"Multiple ar*-ar*-cl* folders found: \"\n",
    "        f\"{[os.path.basename(f) for f in ar_folders]}. \"\n",
    "        \"Exactly one is required.\"\n",
    "    )\n",
    "else:\n",
    "    ar_foldername = os.path.basename(ar_folders[0])\n",
    "\n",
    "# ---- Check .serialized.bin(s) inside ar* folder ----\n",
    "ar_bins = glob.glob(os.path.join(context_path, ar_foldername, \"*.serialized.bin\"))\n",
    "if not ar_bins:\n",
    "    missing.append(\"*.serialized.bin inside ar*-ar*-cl* folder\")\n",
    "\n",
    "# ---- Check embedding_weights*.raw ----\n",
    "embed_files = glob.glob(os.path.join(context_path, \"embedding_weights*.raw\"))\n",
    "embed_weights_filename = embed_files[0] if embed_files else None\n",
    "\n",
    "if embed_weights_filename is None:\n",
    "    missing.append(\"embedding_weights*.raw\")\n",
    "else:\n",
    "    embed_weights_filename = os.path.basename(embed_weights_filename)\n",
    "\n",
    "# ---- Required raw files ----\n",
    "required_raws = [\n",
    "    \"mask.raw\",\n",
    "    \"position_ids_cos.raw\",\n",
    "    \"position_ids_sin.raw\"\n",
    "]\n",
    "\n",
    "for raw in required_raws:\n",
    "    if not os.path.isfile(os.path.join(context_path, raw)):\n",
    "        missing.append(raw)\n",
    "\n",
    "# ---- Check serialized_binaries folder ----\n",
    "serialized_dir = os.path.join(context_path, \"serialized_binaries\")\n",
    "if not os.path.isdir(serialized_dir):\n",
    "    missing.append(\"serialized_binaries/\")\n",
    "else:\n",
    "    serialized_bins = glob.glob(os.path.join(serialized_dir, \"*.serialized.bin\"))\n",
    "    if not serialized_bins:\n",
    "        missing.append(\"*.serialized.bin inside serialized_binaries/\")\n",
    "\n",
    "# ---- Check JSON files ----\n",
    "required_jsons = [\"inputs.json\", \"tokenizer.json\"]\n",
    "for jf in required_jsons:\n",
    "    if not os.path.isfile(os.path.join(context_path, jf)):\n",
    "        missing.append(jf)\n",
    "\n",
    "# ---- Final validation ----\n",
    "if missing:\n",
    "    print(\"Missing required files/folders:\")\n",
    "    for m in missing:\n",
    "        print(f\"  - {m}\")\n",
    "    raise RuntimeError(\"Validation failed: required contestant_uploads content missing\")\n",
    "\n",
    "print(\"Contestant's upload files passed validation\")\n",
    "\n",
    "inputs_json_path = os.path.join(context_path, \"inputs.json\")\n",
    "\n",
    "with open(inputs_json_path, \"r\") as f:\n",
    "    inputs = json.load(f)\n",
    "\n",
    "# ---- Top-level inputs ----\n",
    "qwen2_vl_processor_input = inputs[\"qwen_vl_processor\"]\n",
    "llm_config_input = inputs[\"llm_config\"]\n",
    "inp_h_input = inputs[\"data_preprocess_inp_h\"]\n",
    "inp_w_input = inputs[\"data_preprocess_inp_w\"]\n",
    "run_veg_n_tokens_input  = inputs[\"run_veg_n_tokens\"]\n",
    "run_veg_embedding_dim_input  = inputs[\"run_veg_embedding_dim\"]\n",
    "# ---- Genie config ----\n",
    "genie_config = inputs[\"genie_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdee7156-5865-4c69-8ae8-b436b6fcf84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to: d2d2c4d6\n"
     ]
    }
   ],
   "source": [
    "ADB = \"/mnt/c/platform-tools/adb.exe\"\n",
    "cmd = f'{ADB} devices -l'  # command as a single string\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, shell=True)\n",
    "\n",
    "# Example result:\n",
    "    # List of devices attached\n",
    "    # d2d2c4d6               device product:canoe model:Canoe_for_arm64 device:canoe transport_id:1\n",
    "\n",
    "lines = [line.strip() for line in result.stdout.splitlines() if line.strip()]\n",
    "device_lines = lines[1:]  # Everything after the header\n",
    "\n",
    "if not device_lines:\n",
    "    raise RuntimeError(\"Error: No devices found.\")\n",
    "\n",
    "device_id = device_lines[0].split()[0]\n",
    "print(f\"Successfully connected to: {device_id}\")\n",
    "\n",
    "# Set up NSP Target\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Change GEN4 here to GEN5\n",
    "nsp_target = NspTargets.Android.GEN5 # For GEN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b116d4-ba9e-40d2-ae9b-a962aba3a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/to_device/models/qwen2-vl/tokenizer.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure QNN SDK and Genie paths\n",
    "# Link /qnn_assets to /qnn\n",
    "if os.path.isdir(\"qnn_assets\"):\n",
    "    os.unlink(\"qnn_assets\")\n",
    "os.symlink(\"/qnn\", \"qnn_assets\")\n",
    "\n",
    "execution_ws = os.getcwd()\n",
    "QNN_SDK_dir = os.path.join(execution_ws, \"qnn_assets\")\n",
    "QNN_lib_dir = os.path.join(QNN_SDK_dir, \"lib/aarch64-android\")\n",
    "QNN_binary = os.path.join(QNN_SDK_dir, \"bin/aarch64-android/qnn-net-run\")\n",
    "GENIE_lib_dir = os.path.join(QNN_SDK_dir, \"lib/aarch64-android\")\n",
    "GENIE_binary = os.path.join(QNN_SDK_dir, \"bin/aarch64-android/genie-t2t-run\")\n",
    "QNN_skel = os.path.join(QNN_SDK_dir, \"lib/hexagon-\" + nsp_target.dsp_arch,  \"unsigned\", \"lib\" + nsp_target.qnn_htp_lib_name + \"Skel.so\")\n",
    "\n",
    "des_dir = os.path.join(execution_ws, \"to_device\")\n",
    "# Sub directories of des_dir for Qualla directory structure:\n",
    "des_dir_models = os.path.join(des_dir, \"models\")\n",
    "des_dir_qwen2_models = os.path.join(des_dir_models, \"qwen2-vl\")\n",
    "des_dir_qwen2_models_2B = os.path.join(des_dir_qwen2_models, \"2B-FT\")\n",
    "des_dir_qwen2_model_2B_data = os.path.join(des_dir_qwen2_models_2B, \"data\")\n",
    "\n",
    "if os.path.exists(des_dir):\n",
    "    shutil.rmtree(des_dir) # clear destination dir \n",
    "os.makedirs(des_dir_qwen2_model_2B_data) # will recursively create all required directories\n",
    "\n",
    "# on device destination directories\n",
    "target_device_dir = \"/data/local/tmp/qwen2_vl_assets\"\n",
    "\n",
    "# This is the path of the prepared model binaries for Qwen2-VL (example2)\n",
    "qwen2_models_context_path = os.path.join(context_path, ar_foldername) # MIGHT NEED TO CHANGE THIS LATER ON\n",
    "\n",
    "# This is the list of split LLM model files (in order):\n",
    "llm_model_names = os.listdir(qwen2_models_context_path)\n",
    "llm_model_names.sort()\n",
    "llm_model_names = [f for f in llm_model_names if os.path.isfile(os.path.join(qwen2_models_context_path, f))]\n",
    "\n",
    "veg_models_context_path = os.path.join(context_path + \"/serialized_binaries\")\n",
    "\n",
    "for model_bin in os.listdir(veg_models_context_path):\n",
    "    src_file = os.path.join(veg_models_context_path, model_bin)\n",
    "    # Only copy files, skip directories\n",
    "    if os.path.isfile(src_file):\n",
    "        shutil.copy(src_file, des_dir)\n",
    "\n",
    "# Copy model binaries \n",
    "for model_bin in os.listdir(qwen2_models_context_path):\n",
    "    src_file = os.path.join(qwen2_models_context_path, model_bin)\n",
    "    if os.path.isfile(src_file):\n",
    "        shutil.copy(src_file, des_dir_qwen2_models_2B)\n",
    "\n",
    "qwen2_vl_embedding_buffer_file = os.path.join(context_path, embed_weights_filename)\n",
    "shutil.copy(qwen2_vl_embedding_buffer_file, des_dir_qwen2_models_2B)\n",
    "\n",
    "# Copy necessary libraries to a common location\n",
    "QNN_libs = [\"libQnnHtp.so\", \"libQnnHtpNetRunExtensions.so\", \"libQnnHtpPrepare.so\", \"lib\" + nsp_target.qnn_htp_lib_name + \"Stub.so\", \"libQnnSystem.so\"]\n",
    "for lib in QNN_libs:\n",
    "    shutil.copy(os.path.join(QNN_lib_dir, lib), des_dir)\n",
    "\n",
    "GENIE_libs = [\"libGenie.so\"]\n",
    "for lib in GENIE_libs:\n",
    "    shutil.copy(os.path.join(GENIE_lib_dir, lib), des_dir)\n",
    "\n",
    "# Copy binaries\n",
    "shutil.copy(QNN_binary, des_dir)\n",
    "shutil.copy(GENIE_binary, des_dir)\n",
    "\n",
    "# Copy Skel\n",
    "shutil.copy(QNN_skel, des_dir)\n",
    "\n",
    "qwen2_vl_tokenizer_path = context_path + \"/tokenizer.json\"\n",
    "shutil.copy(qwen2_vl_tokenizer_path, des_dir_qwen2_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b37da2-484a-496f-84c7-c76754590a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htp_backend_extensions.json goes inside the LLM model data folder:\n",
    "qwen2_data_folder_rel_path = os.path.relpath(des_dir_qwen2_model_2B_data, des_dir)\n",
    "target_device_data_dir = os.path.join(target_device_dir, qwen2_data_folder_rel_path)\n",
    "\n",
    "# HTP backend extensions config file (htp_backend_extensions.json) example\n",
    "htp_backend_extensions_data = {\n",
    "    \"backend_extensions\": {\n",
    "        \"shared_library_path\": \"libQnnHtpNetRunExtensions.so\",\n",
    "        \"config_file_path\": os.path.join(target_device_data_dir, \"htp_backend_ext_config.json\")\n",
    "    }\n",
    "}\n",
    "\n",
    "# HTP backend config file (htp_backend_ext_config.json) example\n",
    "htp_backend_ext_config_data = {\n",
    "    \"devices\": [\n",
    "        {\n",
    "            \"cores\":[{\n",
    "                \"perf_profile\": \"burst\",\n",
    "                \"rpc_control_latency\": 100\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# write the config files to the destination\n",
    "with open(os.path.join(des_dir, 'htp_backend_extensions.json'),'w') as f:\n",
    "    f.write(json.dumps(htp_backend_extensions_data, indent=4))\n",
    "# Genie and QNN will use the same htp_backend_ext_config_data, so it will be dumped to the location expected by Genie\n",
    "with open(os.path.join(des_dir_qwen2_model_2B_data,  'htp_backend_ext_config.json'),'w') as f:\n",
    "    f.write(json.dumps(htp_backend_ext_config_data, indent=4))\n",
    "\n",
    "dialog = genie_config[\"dialog\"]\n",
    "\n",
    "# tokenizer\n",
    "dialog[\"tokenizer\"][\"path\"] = str(\n",
    "    \"models/qwen2-vl/tokenizer.json\"\n",
    ")\n",
    "\n",
    "# backend extensions\n",
    "dialog[\"engine\"][\"backend\"][\"extensions\"] = str(\n",
    "    \"models/qwen2-vl/2B-FT/data/htp_backend_ext_config.json\"\n",
    ")\n",
    "\n",
    "BASE_MODEL_DIR = Path(\"models/qwen2-vl/2B-FT\")\n",
    "\n",
    "# ctx-bins (supports multiple files)\n",
    "dialog[\"engine\"][\"model\"][\"binary\"][\"ctx-bins\"] = [\n",
    "    str(BASE_MODEL_DIR / name) for name in llm_model_names\n",
    "]\n",
    "\n",
    "with open(os.path.join(des_dir, 'qwen2-vl-e2t-htp.json'), 'w') as f:\n",
    "    f.write(json.dumps(genie_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c09a22d-8e08-4e72-a7df-3f7c578d70c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: remove target directory from the device if retrying these steps\n",
    "# Changed for WSL:\n",
    "RH = \"localhost\"\n",
    "cmd_rm = [\n",
    "    ADB,\n",
    "    \"-H\", RH,\n",
    "    \"-s\", device_id,\n",
    "    \"shell\", \"rm\", \"-rf\", target_device_dir\n",
    "]\n",
    "result_rm = subprocess.run(cmd_rm, capture_output=True, text=True)\n",
    "print(result_rm.stdout, result_rm.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ffd789f-6850-4400-9cdd-e0324f034640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping directory: /home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/to_device\n",
      "\tZipping completed in 5.26s\n",
      "Pushing ZIP to device...\n",
      "adb push time: 89.54s\n",
      "\n",
      "Unzipping on device...\n",
      "\tadb unzip time: 1.11s\n",
      "Removing ZIPs from device and host...\n",
      "\n",
      "Total time: 95.91s\n"
     ]
    }
   ],
   "source": [
    "zip_path = os.path.join(des_dir, \"package.zip\")\n",
    "device_zip_path = f\"{target_device_dir}/package.zip\"\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    os.remove(zip_path)\n",
    "\n",
    "zip_path = os.path.join(os.path.dirname(des_dir), \"package.zip\")\n",
    "device_zip_path = f\"{target_device_dir}/package.zip\"\n",
    "# --- 1. create ZIP ---\n",
    "print(\"Zipping directory:\", des_dir)\n",
    "t0 = time.time()\n",
    "with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_STORED) as zipf:\n",
    "    for root, dirs, files in os.walk(des_dir):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(full_path, des_dir)\n",
    "            zipf.write(full_path, arcname)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"\\tZipping completed in {t1 - t0:.2f}s\")\n",
    "\n",
    "# --- 2. adb push ZIP ---\n",
    "print(\"Pushing ZIP to device...\")\n",
    "cmd_push = [\n",
    "    ADB, \"-H\", RH, \"-s\", device_id,\n",
    "    \"push\", zip_path, device_zip_path\n",
    "]\n",
    "\n",
    "t2 = time.time()\n",
    "proc_push = subprocess.run(cmd_push, capture_output=True, text=True)\n",
    "t3 = time.time()\n",
    "\n",
    "# print(\"adb push stdout:\", proc_push.stdout)\n",
    "# print(\"adb push stderr:\", proc_push.stderr)\n",
    "print(f\"adb push time: {t3 - t2:.2f}s\\n\")\n",
    "\n",
    "# --- 3. adb unzip ---\n",
    "print(\"Unzipping on device...\")\n",
    "cmd_unzip = (\n",
    "    f'{ADB} -H {RH} -s {device_id} shell \"cd {target_device_dir} && unzip -o package.zip\"'\n",
    ")\n",
    "\n",
    "t4 = time.time()\n",
    "proc_unzip = subprocess.run(cmd_unzip, shell=True, capture_output=True, text=True)\n",
    "t5 = time.time()\n",
    "\n",
    "print(f\"\\tadb unzip time: {t5 - t4:.2f}s\")\n",
    "\n",
    "# --- 4. Remove ZIP from device and host ---\n",
    "print(\"Removing ZIPs from device and host...\")\n",
    "subprocess.run([\n",
    "    ADB, \"-H\", RH, \"-s\", device_id,\n",
    "    \"shell\", \"rm\", \"-f\", device_zip_path\n",
    "], capture_output=True, text=True)\n",
    "os.remove(zip_path)\n",
    "\n",
    "print(f\"\\nTotal time: {t5 - t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd2fe4e-bd86-4c39-a666-da129abab36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Lookup table using:\n",
    "lookup_table_np = np.fromfile(os.path.join(des_dir_qwen2_models_2B, embed_weights_filename), dtype=np.float32) # CHANGE\n",
    "# Reshape lookup table to n-vocab x embedding_vector_len\n",
    "lookup_table_np = lookup_table_np.reshape(genie_config[\"dialog\"][\"context\"][\"n-vocab\"], genie_config[\"dialog\"][\"embedding\"][\"size\"])\n",
    "def get_embeddings(token_ids):\n",
    "    token_embeddings =  []\n",
    "    # Get embedding for each token:\n",
    "    for token_id in token_ids:\n",
    "        token_embeddings.append(lookup_table_np[token_id, :])\n",
    "    # Stack all token embeddings together:\n",
    "    token_embeddings_np = np.stack(token_embeddings, axis=0)\n",
    "    return token_embeddings_np\n",
    "\n",
    "qwen2_vl_processor = AutoProcessor.from_pretrained(qwen2_vl_processor_input) # CHANGE\n",
    "\n",
    "def data_preprocess(processor, img_path, inp_h=342, inp_w=512, prompt=''):\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": img_path,\n",
    "                \"resized_height\": inp_h,\n",
    "                \"resized_width\": inp_w,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "        ],\n",
    "    }]\n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=text,\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "# Define generic qnn-net-run block\n",
    "def run_qnn_net_run(model_context, input_data_list):\n",
    "    # Define tmp directory path for intermediate artifacts\n",
    "    tmp_dirpath = os.path.abspath('tmp/inputs')\n",
    "    os.makedirs(tmp_dirpath, exist_ok=True)\n",
    "    \n",
    "    # Dump each input data from input_data_list as raw file\n",
    "    # and prepare input_list_filepath for qnn-net-run\n",
    "    input_list_text = ''\n",
    "    for index, input_data in enumerate(input_data_list):\n",
    "        # Create and dump each input into raw file\n",
    "        raw_file_path = f'{tmp_dirpath}/input_{index}.raw'\n",
    "        input_data.tofile(raw_file_path)\n",
    "        # Keep appending raw_file_path into input_list_text for input_list_filepath file\n",
    "        input_list_text += target_device_dir + '/inputs/' + os.path.basename(raw_file_path) + ' '\n",
    "\n",
    "    cos_data  = os.path.join(context_path, \"position_ids_cos.raw\")\n",
    "    sin_data  = os.path.join(context_path, \"position_ids_sin.raw\")\n",
    "    mask_data = os.path.join(context_path, \"mask.raw\")\n",
    "    shutil.copy(cos_data, tmp_dirpath)\n",
    "    shutil.copy(sin_data, tmp_dirpath)\n",
    "    shutil.copy(mask_data, tmp_dirpath)\n",
    "    input_list_text += target_device_dir + '/inputs/position_ids_cos.raw' + ' '\n",
    "    input_list_text += target_device_dir + '/inputs/position_ids_sin.raw' + ' '\n",
    "    input_list_text += target_device_dir + '/inputs/mask.raw' + ' '\n",
    "\n",
    "    print(input_list_text)\n",
    "    \n",
    "    # Create input_list_filepath and add prepared input_list_text into this file\n",
    "    input_list_filepath = f'{tmp_dirpath}/../input_list.txt'\n",
    "    with open(input_list_filepath, 'w') as f:\n",
    "        f.write(input_list_text)\n",
    "\n",
    "    # Push input_list_filepath and input data raw files to device\n",
    "    !{ADB} -H {RH} -s {device_id} push {input_list_filepath} {target_device_dir} > /dev/null\n",
    "    !{ADB} -H {RH} -s {device_id} push {tmp_dirpath} {target_device_dir} > /dev/null\n",
    "    \n",
    "    # Execute qnn-net-run on shell\n",
    "    !{ADB} -H {RH} -s {device_id} shell LD_LIBRARY_PATH={target_device_dir} ADSP_LIBRARY_PATH={target_device_dir} \\\n",
    "    {target_device_dir}/qnn-net-run --retrieve_context {model_context} --backend {target_device_dir}/libQnnHtp.so \\\n",
    "    --input_list {target_device_dir}/input_list.txt --output_dir {target_device_dir} \\\n",
    "    --config_file {target_device_dir}/htp_backend_extensions.json > {tmp_dirpath}/log.txt\n",
    "\n",
    "    # Pull the output file from device\n",
    "    !{ADB} -H {RH} -s {device_id} pull {target_device_dir}/Result_0/vision_embedding.raw {tmp_dirpath} > /dev/null\n",
    "    \n",
    "    # Read the output data generated by qnn-net-run\n",
    "    output_data = np.fromfile(f'{tmp_dirpath}/vision_embedding.raw', dtype=np.float32)\n",
    "    \n",
    "    # Delete all intermediate artifacts\n",
    "    # shutil.rmtree(tmp_dirpath)\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "def run_veg(pixel_values, n_tokens=216, embedding_dim=1536):\n",
    "    input_data_list = [pixel_values]\n",
    "    output_data = run_qnn_net_run(f'{target_device_dir}/veg.serialized.bin', input_data_list)\n",
    "    # VEG output should be of shape (1, 529, 1536) \n",
    "    # (640. 640) -> (644, 644) -> (46  46) -> 529 = 46 * 46 / 4\n",
    "    # (342, 512) -> (336, 504) -> (24, 36) -> 24 * 36 /4 =  216\n",
    "    output_data = output_data.reshape((1, n_tokens, embedding_dim))\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5b4caa-b35e-490f-8fb2-1b48a413042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory on device: /data/local/tmp/qwen2_vl_assets/ImageEmbeds\n",
      "Found 10 images and 2 prompt variations.\n",
      "Running Vision Encoder for kev2...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.007s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 25.8 MB/s (8654337 bytes in 0.321s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 24.8 MB/s (1327104 bytes in 0.051s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kev2_prompt2.raw\n",
      "Generated kev2_prompt1.raw\n",
      "Running Vision Encoder for kev5...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.008s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 24.8 MB/s (8654337 bytes in 0.333s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 19.1 MB/s (1327104 bytes in 0.066s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kev5_prompt2.raw\n",
      "Generated kev5_prompt1.raw\n",
      "Running Vision Encoder for SDXL_catA_p5...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.005s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 25.3 MB/s (8654337 bytes in 0.327s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 17.6 MB/s (1327104 bytes in 0.072s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SDXL_catA_p5_prompt2.raw\n",
      "Generated SDXL_catA_p5_prompt1.raw\n",
      "Running Vision Encoder for SDXL_catA_p4...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.009s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 33.8 MB/s (8654337 bytes in 0.244s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 18.4 MB/s (1327104 bytes in 0.069s)\n",
      "Generated SDXL_catA_p4_prompt2.raw\n",
      "Generated SDXL_catA_p4_prompt1.raw\n",
      "Running Vision Encoder for SDXL_catA_p3...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.008s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 34.4 MB/s (8654337 bytes in 0.240s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 18.9 MB/s (1327104 bytes in 0.067s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SDXL_catA_p3_prompt2.raw\n",
      "Generated SDXL_catA_p3_prompt1.raw\n",
      "Running Vision Encoder for kev1...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.008s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 21.2 MB/s (8654337 bytes in 0.388s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 15.0 MB/s (1327104 bytes in 0.084s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kev1_prompt2.raw\n",
      "Generated kev1_prompt1.raw\n",
      "Running Vision Encoder for SDXL_catA_p2...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.011s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 25.4 MB/s (8654337 bytes in 0.325s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 19.4 MB/s (1327104 bytes in 0.065s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SDXL_catA_p2_prompt2.raw\n",
      "Generated SDXL_catA_p2_prompt1.raw\n",
      "Running Vision Encoder for SDXL_catA_p1...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.010s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 23.9 MB/s (8654337 bytes in 0.346s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 23.8 MB/s (1327104 bytes in 0.053s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SDXL_catA_p1_prompt2.raw\n",
      "Generated SDXL_catA_p1_prompt1.raw\n",
      "Running Vision Encoder for kev3...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.015s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 26.6 MB/s (8654337 bytes in 0.310s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 19.7 MB/s (1327104 bytes in 0.064s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kev3_prompt2.raw\n",
      "Generated kev3_prompt1.raw\n",
      "Running Vision Encoder for kev4...\n",
      "/data/local/tmp/qwen2_vl_assets/inputs/input_0.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_cos.raw /data/local/tmp/qwen2_vl_assets/inputs/position_ids_sin.raw /data/local/tmp/qwen2_vl_assets/inputs/mask.raw \n",
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs/../input_list.txt: 1 file pushed, 0 skipped. 0.0 MB/s (219 bytes in 0.007s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacks/Tutorial_for_Qwen2_VL_2b_IoT/inference_script/tmp/inputs\\: 6 files pushed, 0 skipped. 34.8 MB/s (8654337 bytes in 0.237s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Result_0/vision_embedding.raw: 1 file pulled, 0 skipped. 19.8 MB/s (1327104 bytes in 0.064s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated kev4_prompt2.raw\n",
      "Generated kev4_prompt1.raw\n",
      "\n",
      "Zipping all embeddings → all_image_prompt_embeddings.zip\n",
      "Pushing zip to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp/all_image_prompt_embeddings.zip: 1 file pushed, 0 skipped. 38.4 MB/s (29862182 bytes in 0.742s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping on device...\n",
      "Archive:  all_image_prompt_embeddings.zip\n",
      "  inflating: SDXL_catA_p5_prompt2.raw\n",
      "  inflating: SDXL_catA_p1_prompt2.raw\n",
      "  inflating: kev2_prompt2.raw\n",
      "  inflating: SDXL_catA_p1_prompt1.raw\n",
      "  inflating: SDXL_catA_p3_prompt1.raw\n",
      "  inflating: SDXL_catA_p3_prompt2.raw\n",
      "  inflating: SDXL_catA_p4_prompt1.raw\n",
      "  inflating: kev4_prompt2.raw\n",
      "  inflating: kev5_prompt2.raw\n",
      "  inflating: SDXL_catA_p2_prompt2.raw\n",
      "  inflating: kev3_prompt2.raw\n",
      "  inflating: kev1_prompt1.raw\n",
      "  inflating: kev1_prompt2.raw\n",
      "  inflating: SDXL_catA_p4_prompt2.raw\n",
      "  inflating: kev4_prompt1.raw\n",
      "  inflating: kev2_prompt1.raw\n",
      "  inflating: SDXL_catA_p5_prompt1.raw\n",
      "  inflating: kev5_prompt1.raw\n",
      "  inflating: kev3_prompt1.raw\n",
      "  inflating: SDXL_catA_p2_prompt1.raw\n",
      "All embeddings processed, zipped, pushed, and unzipped on device\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "host_image_folder = \"dataset/images\"\n",
    "host_prompts_folder = \"dataset/prompts\"\n",
    "device_embeds_dir = f\"{target_device_dir}/ImageEmbeds\"\n",
    "llm_config = AutoConfig.from_pretrained(\n",
    "    llm_config_input, # CHANGE: let contestants config this model name\n",
    "    trust_remote_code=True\n",
    ") \n",
    "\n",
    "# --- Ensure Device Directory Exists ---\n",
    "print(f\"Creating directory on device: {device_embeds_dir}\")\n",
    "subprocess.run(\n",
    "    f'{ADB} -H {RH} -s {device_id} shell \"mkdir -p {device_embeds_dir}\"', \n",
    "    shell=True, \n",
    "    check=True\n",
    ")\n",
    "\n",
    "# --- Prepare File Lists ---\n",
    "image_files = glob.glob(os.path.join(host_image_folder, \"*.png\"))\n",
    "prompt_files = glob.glob(os.path.join(host_prompts_folder, \"*.txt\"))\n",
    "print(f\"Found {len(image_files)} images and {len(prompt_files)} prompt variations.\")\n",
    "\n",
    "TMP_ROOT = Path(\"tmp\")\n",
    "TMP_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Processing Loop\n",
    "for img_path in image_files:\n",
    "    img_name_root = Path(img_path).stem\n",
    "\n",
    "    # 1. Image Preprocessing & Vision Encoder (Done ONCE per image)\n",
    "    try:\n",
    "        temp_inputs = data_preprocess(qwen2_vl_processor, img_path, inp_h_input, inp_w_input, \"\")\n",
    "        pixel_values = temp_inputs['pixel_values'].detach().numpy().astype(np.float32)\n",
    "\n",
    "        print(f\"Running Vision Encoder for {img_name_root}...\")\n",
    "        image_embeddings_raw = run_veg(pixel_values)\n",
    "        image_embeddings_torch = torch.from_numpy(image_embeddings_raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process image {img_name_root}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 2. Prompt Loop (Combine the fixed image with each unique prompt)\n",
    "    for prompt_path in prompt_files:\n",
    "        prompt_name = Path(prompt_path).stem\n",
    "        raw_filename = f\"{img_name_root}_{prompt_name}.raw\"\n",
    "        raw_path = TMP_ROOT / raw_filename\n",
    "\n",
    "        try:\n",
    "            with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                prompt_text = f.read()\n",
    "\n",
    "            # Preprocess text with the image\n",
    "            inputs = data_preprocess(qwen2_vl_processor, img_path, inp_h_input, inp_w_input, prompt_text)\n",
    "            token_ids = inputs['input_ids']\n",
    "\n",
    "            # Generate Text Embeddings locally\n",
    "            inputs_embeds = torch.from_numpy(get_embeddings(token_ids))\n",
    "\n",
    "            # Masking logic to insert cached image embeddings into new text embeddings\n",
    "            image_mask = ((inputs['input_ids'] == llm_config.image_token_id)\n",
    "                          .unsqueeze(-1)\n",
    "                          .expand_as(inputs_embeds))\n",
    "\n",
    "            # Combine\n",
    "            final_embeds = inputs_embeds.masked_scatter(image_mask, image_embeddings_torch).detach().numpy()\n",
    "\n",
    "            final_embeds.tofile(raw_path)\n",
    "            print(f\"Generated {raw_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> Failed prompt {prompt_name} for image {img_name_root}: {e}\")\n",
    "\n",
    "# --- 3. Zip everything once ---\n",
    "zip_path = TMP_ROOT / \"all_image_prompt_embeddings.zip\"\n",
    "print(f\"\\nZipping all embeddings → {zip_path.name}\")\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_STORED) as zf:\n",
    "    for raw_file in TMP_ROOT.glob(\"*.raw\"):\n",
    "        zf.write(raw_file, arcname=raw_file.name)\n",
    "\n",
    "# --- 4. Push zip to device ---\n",
    "print(\"Pushing zip to device...\")\n",
    "subprocess.run(\n",
    "    f'{ADB} -H {RH} -s {device_id} push {zip_path} {device_embeds_dir}/',\n",
    "    shell=True,\n",
    "    check=True\n",
    ")\n",
    "\n",
    "# --- 5. Unzip on device ---\n",
    "print(\"Unzipping on device...\")\n",
    "subprocess.run(\n",
    "    f'{ADB} -H {RH} -s {device_id} shell '\n",
    "    f'\"cd {device_embeds_dir} && unzip -o {zip_path.name}\"',\n",
    "    shell=True,\n",
    "    check=True\n",
    ")\n",
    "\n",
    "# --- 6. Cleanup ---\n",
    "for raw_file in TMP_ROOT.glob(\"*.raw\"):\n",
    "    raw_file.unlink()\n",
    "zip_path.unlink()\n",
    "\n",
    "print(\"All embeddings processed, zipped, pushed, and unzipped on device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0b4ae5-d7a5-4400-99ca-c5c0d6f7e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing batch script to device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch_run.sh: 1 file pushed, 0 skipped. 0.1 MB/s (1074 bytes in 0.020s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting continuous batch inference on device...\n",
      "Starting Batch Inference...\n",
      "Running SDXL_catA_p1_prompt1.raw...\n",
      "Running SDXL_catA_p1_prompt2.raw...\n",
      "Running SDXL_catA_p2_prompt1.raw...\n",
      "Running SDXL_catA_p2_prompt2.raw...\n",
      "Running SDXL_catA_p3_prompt1.raw...\n",
      "Running SDXL_catA_p3_prompt2.raw...\n",
      "Running SDXL_catA_p4_prompt1.raw...\n",
      "Running SDXL_catA_p4_prompt2.raw...\n",
      "Running SDXL_catA_p5_prompt1.raw...\n",
      "Running SDXL_catA_p5_prompt2.raw...\n",
      "Running kev1_prompt1.raw...\n",
      "Running kev1_prompt2.raw...\n",
      "Running kev2_prompt1.raw...\n",
      "Running kev2_prompt2.raw...\n",
      "Running kev3_prompt1.raw...\n",
      "Running kev3_prompt2.raw...\n",
      "Running kev4_prompt1.raw...\n",
      "Running kev4_prompt2.raw...\n",
      "Running kev5_prompt1.raw...\n",
      "Running kev5_prompt2.raw...\n",
      "Batch processing complete. Processed 20 files.\n",
      "Device finished execution.\n",
      "\n",
      "Pulling inference outputs...\n",
      "Pulling timing summary...\n",
      "\n",
      "Total Host Wall-Clock Time: 50.30 seconds\n",
      "Results saved to: HostOutputs/\n",
      "Timing log saved to: HostOutputs/timing_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/qwen2_vl_assets/Outputs/./: 20 files pulled, 0 skipped. 0.1 MB/s (10382 bytes in 0.085s)\n",
      "/data/local/tmp/qwen2_vl_assets/timing_summary.txt: 1 file pulled, 0 skipped. 1.1 MB/s (4400 bytes in 0.004s)\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Paths\n",
    "device_output_dir = \"Outputs\"      # Relative to target_device_dir\n",
    "host_output_dir = \"Host_Outputs\"    # Local folder for results to pull into\n",
    "os.makedirs(host_output_dir, exist_ok=True)\n",
    "\n",
    "# --- 1. Define the Batch Script ---\n",
    "batch_script_content = f\"\"\"#!/bin/sh\n",
    "cd {target_device_dir}\n",
    "export LD_LIBRARY_PATH={target_device_dir}\n",
    "export ADSP_LIBRARY_PATH={target_device_dir}\n",
    "\n",
    "# Clean and create output directories\n",
    "rm -rf {device_output_dir}\n",
    "mkdir -p {device_output_dir}\n",
    "\n",
    "# Use a count to track if anything actually gets done\n",
    "count=0\n",
    "\n",
    "for f in {device_embeds_dir}/*.raw; do\n",
    "    # Strict check to see if the file exists\n",
    "    [ -e \"$f\" ] || continue\n",
    "    \n",
    "    filename=$(basename \"$f\")\n",
    "    output_name=\"${{filename%.*}}.txt\"\n",
    "    \n",
    "    echo \"------------------------------------------------\" >> timing_summary.txt\n",
    "    echo \"$filename\" >> timing_summary.txt\n",
    "    echo \"Running $filename...\"\n",
    "    \n",
    "    {{ time ./genie-t2t-run \\\\\n",
    "        -c qwen2-vl-e2t-htp.json \\\\\n",
    "        -e \"$f\" \\\\\n",
    "        -t models/qwen2-vl/2B-FT/{embed_weights_filename} \\\\\n",
    "        > \"{device_output_dir}/$output_name\"; }} 2>> timing_summary.txt\n",
    "    \n",
    "    count=$((count + 1))\n",
    "done\n",
    "\n",
    "echo \"\\nBatch processing complete. Processed $count files.\"\n",
    "\"\"\"\n",
    "\n",
    "script_name = \"batch_run.sh\"\n",
    "# Use newline='\\n' to ensure Linux line endings for the script\n",
    "with open(script_name, \"w\", newline='\\n') as f:\n",
    "    f.write(batch_script_content)\n",
    "\n",
    "# --- 2. Push Script & Prepare Device ---\n",
    "print(\"Pushing batch script to device...\")\n",
    "subprocess.run(f'{ADB} -H {RH} -s {device_id} push {script_name} {target_device_dir}/', shell=True, check=True)\n",
    "subprocess.run(f'{ADB} -H {RH} -s {device_id} shell \"chmod +x {target_device_dir}/{script_name}\"', shell=True, check=True)\n",
    "\n",
    "# --- 3. Execute Batch Script (One ADB Call) ---\n",
    "print(\"\\nStarting continuous batch inference on device...\")\n",
    "host_start_time = time.time()\n",
    "\n",
    "# This command triggers the script and blocks until it finishes\n",
    "cmd = f'{ADB} -H {RH} -s {device_id} shell \"{target_device_dir}/{script_name}\"'\n",
    "process = subprocess.run(cmd, shell=True)\n",
    "\n",
    "host_end_time = time.time()\n",
    "\n",
    "if process.returncode != 0:\n",
    "    print(\"Error occurred during batch execution. Check connection.\")\n",
    "else:\n",
    "    print(\"Device finished execution.\")\n",
    "\n",
    "# --- 4. Pull Results and Timing Logs ---\n",
    "print(\"\\nPulling inference outputs...\")\n",
    "# Pull the folder containing all output text files\n",
    "subprocess.run(f'{ADB} -H {RH} -s {device_id} pull {target_device_dir}/{device_output_dir}/. {host_output_dir}/', shell=True, check=True)\n",
    "\n",
    "print(\"Pulling timing summary...\")\n",
    "# Pull the timing log file\n",
    "subprocess.run(f'{ADB} -H {RH} -s {device_id} pull {target_device_dir}/timing_summary.txt {host_output_dir}/', shell=True, check=True)\n",
    "\n",
    "# --- 5. Report ---\n",
    "total_duration = host_end_time - host_start_time\n",
    "print(f\"\\nTotal Host Wall-Clock Time: {total_duration:.2f} seconds\")\n",
    "print(f\"Results saved to: {host_output_dir}/\")\n",
    "print(f\"Timing log saved to: {host_output_dir}/timing_summary.txt\")\n",
    "\n",
    "# Cleanup local script file\n",
    "if os.path.exists(script_name):\n",
    "    os.remove(script_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2-vl_env",
   "language": "python",
   "name": "qwen2-vl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
